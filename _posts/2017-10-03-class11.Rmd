---
title: "Class 11: Thinking, Fast and Slow"
author: "Taylor Arnold"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE)
knitr::opts_chunk$set(fig.path = "../assets/2017-10-03-class11/")
knitr::opts_chunk$set(fig.height = 5)
knitr::opts_chunk$set(fig.width = 8.5)
knitr::opts_chunk$set(out.width = "100%")
knitr::opts_chunk$set(dpi = 300)
```

```{r, message = FALSE}
library(readr)
library(ggplot2)
library(dplyr)
```




```{r, message = FALSE}
wiki <- read_csv("https://statsmaths.github.io/ml_data/wiki_traffic.csv")
```

$$  X \cdot A =
    \left(\begin{array}{cc} X_{1,1} & X_{1,2} \\
                           X_{1,1} & X_{1,2} \\
                           \vdots & \vdots \\
                           X_{n,1} & X_{n, 2} \end{array} \right) \cdot
    \left(\begin{array}{cc} A_{1,1} & A_{1,2} \\
                            A_{2,1} & A_{2, 2} \end{array} \right)
                            =
   \left(\begin{array}{c} X_{1} \\
                           X_{2} \\
                           \vdots \\
                           X_{n} \end{array} \right) \cdot
    \left(\begin{array}{cc} A^{(0)} & A^{(1)}\end{array} \right)
                            =
   \left(\begin{array}{cc} X_{1} \cdot A^{(0)} & X_{1} \cdot A^{(0)} \\
                           X_{2} \cdot A^{(0)} & X_{2} \cdot A^{(0)} \\
                           \vdots & \vdots \\
                           X_{n} \cdot A^{(0)} & X_{n} \cdot A^{(0)} \end{array} \right)
                        $$

$$ \left( X \cdot A \right) \cdot B, \quad B = \left(\begin{array}{c} b_1 \\ b_2 \end{array}\right) $$

```{r, fig.asp=0.33, fig.width = 12}
par(mfrow = c(1, 3))
plot(0, 0, type = "n", xlim = c(-1, 4), ylim = c(-1, 2),
     axes = FALSE, xlab = "", ylab = "")
abline(0.5, -0.5, lty = "dashed", lwd = 4)
abline(v = 0); abline(h = 0)
box()
plot(0, 0, type = "n", xlim = c(-1, 4), ylim = c(-1, 2),
     axes = FALSE, xlab = "", ylab = "")
mtext("+", side=2, line=2.2, cex=2)
abline(-1, 1, lty = "dashed", lwd = 4)
abline(v = 0); abline(h = 0)
box()
plot(0, 0, type = "n", xlim = c(-1, 4), ylim = c(-1, 2),
     axes = FALSE, xlab = "", ylab = "")
mtext("=", side=2, line=2.2, cex=2, las=1)
abline(-0.5, 0.5, lty = "dashed", col = "orange", lwd = 4)
abline(0.5, -1, lty = "dashed", lwd = 1)
abline(-1, 1, lty = "dashed", lwd = 1)
abline(v = 0); abline(h = 0)
box()
```


```{r, message = FALSE}
library(keras)
```

```{r}
X <- scale(as.matrix(select(wiki, day001)))
y <- scale(wiki$day000)

X_train <- X[wiki$train_id == "train",]
X_valid <- X[wiki$train_id == "valid",]
y_train <- y[wiki$train_id == "train"]
y_valid <- y[wiki$train_id == "valid"]
```

```{r, message = FALSE}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 2, input_shape = c(1)) %>%
  layer_dense(units = 1)
model
```

```{r}
model %>% compile(
  loss = 'mse',
  optimizer = optimizer_rmsprop(),
  metrics = c('mse')
)
```

```{r}
model %>%
  fit(X_train, y_train, epochs = 5,
      validation_data = list(X_valid, y_valid))
```


![](img/tikz40.png)

```{r}
y_valid_pred <- predict(model, X_valid)
qplot(X_valid, y_valid_pred)
```

$$ \sigma \left( X \cdot A \right) \cdot B, \quad B =
    \left(\begin{array}{c} b_1 \\ b_2 \end{array}\right) $$

**rectified linear unit (relu)**:

$$ \sigma(x) =
\begin{cases}
    x,& \text{if } x\geq 0\\
    0,              & \text{otherwise}
\end{cases}  $$


```{r, fig.asp=0.33}
par(mfrow = c(1, 3))
plot(0, 0, type = "n", xlim = c(-1, 4), ylim = c(-1, 2),
     axes = FALSE, xlab = "", ylab = "")
abline(1, -1, lty = "dashed", lwd = 4)
abline(v = 0); abline(h = 0)
box()
plot(0, 0, type = "n", xlim = c(-1, 4), ylim = c(-1, 2),
     axes = FALSE, xlab = "", ylab = "")
mtext("+", side=2, line=2.2, cex=2)
abline(-3, 1, lty = "dashed", lwd = 4)
abline(v = 0); abline(h = 0)
box()
plot(0, 0, type = "n", xlim = c(-1, 4), ylim = c(-1, 2),
     axes = FALSE, xlab = "", ylab = "")
mtext("=", side=2, line=2.2, cex=2, las=1)
lines(x = c(-3, 1, 3, 5), y = c(4, 0, 0, 2), col = "orange",
      lwd = 6, lty = "dashed")
abline(-3, 1, lty = "dashed", lwd = 1)
abline(1, -1, lty = "dashed", lwd = 1)
abline(v = 0); abline(h = 0)
box()
```



```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 2, input_shape = c(1)) %>%
  layer_activation(activation = "relu") %>%
  layer_dense(units = 1)
model
```

```{r}
model %>% compile(
  loss = 'mse',
  optimizer = optimizer_rmsprop(),
  metrics = c('mse')
)
model %>%
  fit(X_train, y_train, epochs = 5,
      validation_data = list(X_valid, y_valid))
```

```{r}
y_valid_pred <- predict(model, X_valid)
qplot(X_valid, y_valid_pred)
```


```{r}
X <- scale(as.matrix(select(wiki, day001, day002, day003, day004)))
y <- scale(wiki$day000)

X_train <- X[wiki$train_id == "train",]
X_valid <- X[wiki$train_id == "valid",]
y_train <- y[wiki$train_id == "train"]
y_valid <- y[wiki$train_id == "valid"]
```

```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 5, input_shape = c(4)) %>%
  layer_activation(activation = "relu") %>%
  layer_dense(units = 3) %>%
  layer_activation(activation = "relu") %>%
  layer_dense(units = 1)
model
```

```{r}
model %>% compile(
  loss = 'mse',
  optimizer = optimizer_rmsprop(),
  metrics = c('mse')
)
model %>%
  fit(X_train, y_train, epochs = 20,
      validation_data = list(X_valid, y_valid))
```



```{r}
y_valid_pred <- predict(model, X_valid)
qplot(X_valid[,1], X_valid[,2], color = y_valid_pred) +
  viridis::scale_color_viridis() +
  scale_x_log10() +
  scale_y_log10()
```




```{r, message = FALSE}
crimes <- read_csv("https://statsmaths.github.io/ml_data/chi_crimes_12.csv")
```

$$ Y = \sigma(X \cdot A) \cdot B $$


```{r}
to_categorical(c(1,1,2,4,10))
```

```{r}
X <- scale(as.matrix(select(crimes, longitude, latitude, hour)))
y <- factor(crimes$crime_type)
crime_levels <- levels(y)
y <- as.integer(y) - 1

X_train <- X[crimes$train_id == "train",]
y_train <- to_categorical(y[crimes$train_id == "train"], num_classes = 12)
X_valid <- X[crimes$train_id == "valid",]
y_valid <- to_categorical(y[crimes$train_id == "valid"], num_classes = 12)
```

```{r}
y_train[sample(nrow(y_train), 10),]
```

```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 20, input_shape = c(3)) %>%
  layer_activation(activation = "relu") %>%
  layer_dense(units = 20) %>%
  layer_activation(activation = "relu") %>%
  layer_dense(units = 12) %>%
  layer_activation(activation = "softmax")
model
```


```{r}
model %>% compile(loss = 'categorical_crossentropy',
                  optimizer = optimizer_rmsprop(),
                  metrics = c('accuracy'))
```

```{r}
model %>%
  fit(X_train, y_train, epochs = 10,
      validation_data = list(X_valid, y_valid))
```

```{r}
crimes <- sample_frac(crimes, size = 1)
X <- scale(as.matrix(select(crimes, longitude, latitude, hour)))
y <- factor(crimes$crime_type)
crime_levels <- levels(y)
y <- as.integer(y) - 1

X_train <- X[crimes$train_id == "train",]
y_train <- to_categorical(y[crimes$train_id == "train"], num_classes = 12)
X_valid <- X[crimes$train_id == "valid",]
y_valid <- to_categorical(y[crimes$train_id == "valid"], num_classes = 12)
```

```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 20, input_shape = c(3)) %>%
  layer_activation(activation = "relu") %>%
  layer_dense(units = 20) %>%
  layer_activation(activation = "relu") %>%
  layer_dense(units = 12) %>%
  layer_activation(activation = "softmax")
model %>% compile(loss = 'categorical_crossentropy',
                  optimizer = optimizer_rmsprop(),
                  metrics = c('accuracy'))
```


```{r}
model %>%
  fit(X_train, y_train, epochs = 10,
      validation_data = list(X_valid, y_valid))
```

```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 20, input_shape = c(3)) %>%
  layer_activation(activation = "relu") %>%
  layer_dropout(rate = 0.1) %>%
  layer_dense(units = 20) %>%
  layer_activation(activation = "relu") %>%
  layer_dropout(rate = 0.1) %>%
  layer_dense(units = 12) %>%
  layer_activation(activation = "softmax")
model %>% compile(loss = 'categorical_crossentropy',
                  optimizer = optimizer_rmsprop(),
                  metrics = c('accuracy'))
```


```{r}
model %>%
  fit(X_train, y_train, epochs = 10,
      validation_data = list(X_valid, y_valid))
```
