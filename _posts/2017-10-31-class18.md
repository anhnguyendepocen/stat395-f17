---
title: "Class 18: Faster, Higher, Stronger (and Deeper!)"
author: "Taylor Arnold"
output: html_notebook
---





{% highlight r %}
library(readr)
library(ggplot2)
library(dplyr)
library(methods)
library(keras)
{% endhighlight %}


{% highlight r %}
mnist <- read_csv("~/files/ml_data/mnist10.csv")
X <- read_rds("~/files/ml_data/mnist10_X.rds")
X <- array(X, dim = c(dim(X), 1))
y <- mnist$class

X_train <- X[mnist$train_id == "train",,,,drop = FALSE]
y_train <- to_categorical(y[mnist$train_id == "train"], num_classes = 10)
{% endhighlight %}


{% highlight r %}
model <- keras_model_sequential()
model %>%
  layer_conv_2d(filters = 32, kernel_size = c(2,2),
                  strides = c(2,2),
                  input_shape = c(28, 28, 1)) %>%
  layer_activation(activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_dropout(rate = 0.5) %>%

  layer_flatten() %>%
  layer_dense(units = 10) %>%
  layer_activation(activation = "softmax")

model %>% compile(loss = 'categorical_crossentropy',
                  optimizer = optimizer_rmsprop(),
                  metrics = c('accuracy'))

model
{% endhighlight %}



{% highlight text %}
## Model
## ___________________________________________________________________________
## Layer (type)                     Output Shape                  Param #     
## ===========================================================================
## conv2d_1 (Conv2D)                (None, 14, 14, 32)            160         
## ___________________________________________________________________________
## activation_1 (Activation)        (None, 14, 14, 32)            0           
## ___________________________________________________________________________
## max_pooling2d_1 (MaxPooling2D)   (None, 7, 7, 32)              0           
## ___________________________________________________________________________
## dropout_1 (Dropout)              (None, 7, 7, 32)              0           
## ___________________________________________________________________________
## flatten_1 (Flatten)              (None, 1568)                  0           
## ___________________________________________________________________________
## dense_1 (Dense)                  (None, 10)                    15690       
## ___________________________________________________________________________
## activation_2 (Activation)        (None, 10)                    0           
## ===========================================================================
## Total params: 15,850
## Trainable params: 15,850
## Non-trainable params: 0
## ___________________________________________________________________________
{% endhighlight %}


{% highlight r %}
history <- model %>%
  fit(X_train, y_train, epochs = 10,
      validation_split = 0.1)
plot(history)
{% endhighlight %}

![plot of chunk unnamed-chunk-4](../assets/2017-10-31-class18/unnamed-chunk-4-1.png)

## Double Convolution


{% highlight r %}
model <- keras_model_sequential()
model %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3),
                  input_shape = c(28, 28, 1)) %>%
  layer_activation(activation = "relu") %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3)) %>%
  layer_activation(activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_dropout(rate = 0.5) %>%

  layer_flatten() %>%
  layer_dense(units = 128) %>%
  layer_activation(activation = "relu") %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 10) %>%
  layer_activation(activation = "softmax")

model %>% compile(loss = 'categorical_crossentropy',
                  optimizer = optimizer_rmsprop(),
                  metrics = c('accuracy'))

model
{% endhighlight %}



{% highlight text %}
## Model
## ___________________________________________________________________________
## Layer (type)                     Output Shape                  Param #     
## ===========================================================================
## conv2d_2 (Conv2D)                (None, 26, 26, 32)            320         
## ___________________________________________________________________________
## activation_3 (Activation)        (None, 26, 26, 32)            0           
## ___________________________________________________________________________
## conv2d_3 (Conv2D)                (None, 24, 24, 32)            9248        
## ___________________________________________________________________________
## activation_4 (Activation)        (None, 24, 24, 32)            0           
## ___________________________________________________________________________
## max_pooling2d_2 (MaxPooling2D)   (None, 12, 12, 32)            0           
## ___________________________________________________________________________
## dropout_2 (Dropout)              (None, 12, 12, 32)            0           
## ___________________________________________________________________________
## flatten_2 (Flatten)              (None, 4608)                  0           
## ___________________________________________________________________________
## dense_2 (Dense)                  (None, 128)                   589952      
## ___________________________________________________________________________
## activation_5 (Activation)        (None, 128)                   0           
## ___________________________________________________________________________
## dropout_3 (Dropout)              (None, 128)                   0           
## ___________________________________________________________________________
## dense_3 (Dense)                  (None, 10)                    1290        
## ___________________________________________________________________________
## activation_6 (Activation)        (None, 10)                    0           
## ===========================================================================
## Total params: 600,810
## Trainable params: 600,810
## Non-trainable params: 0
## ___________________________________________________________________________
{% endhighlight %}


{% highlight r %}
history <- model %>%
  fit(X_train, y_train, epochs = 1,
      validation_split = 0.1)
plot(history)
{% endhighlight %}

![plot of chunk unnamed-chunk-6](../assets/2017-10-31-class18/unnamed-chunk-6-1.png)

## Negative examples again


{% highlight r %}
y_pred <- predict_classes(model, X)
table(y[mnist$train_id == "train"], y_pred[mnist$train_id == "train"])
{% endhighlight %}



{% highlight text %}
##    
##        0    1    2    3    4    5    6    7    8    9
##   0 5840    0    5    3    3    8   48    0    9    7
##   1    1 6674   30    7    5    0    3    7   15    0
##   2   12   25 5804   26   24    0    4   36   22    5
##   3    2    1   30 6027    0   23    3   28    7   10
##   4    3   15   11    0 5749    0   23    4    5   32
##   5    3    2    5   34    4 5311   40    0   12   10
##   6    9    7    2    0   15   33 5846    0    6    0
##   7    6   29   41    7   31    4    0 6113   12   22
##   8   15   32   23   19   23   41   42    6 5610   40
##   9   15   13    4   25   35   22    1   41   17 5776
{% endhighlight %}


{% highlight r %}
par(mar = c(0,0,0,0))
par(mfrow = c(10, 10))
for (i in sample(which(y_pred != y), 100)) {
  plot(0,0,xlim=c(0,1),ylim=c(0,1),axes= FALSE,type = "n")
  rasterImage(X[i,,,],0,0,1,1)
  text(0.1,0.1,y[i],col="blue", cex = 3)
  text(0.9,0.1,y_pred[i],col="red", cex = 3)
  box()
}
{% endhighlight %}

![plot of chunk unnamed-chunk-8](../assets/2017-10-31-class18/unnamed-chunk-8-1.png)

## Visualize the kernels



{% highlight r %}
layer <- get_layer(model, index = 1)
dim(layer$get_weights()[[1]])
{% endhighlight %}



{% highlight text %}
## [1]  3  3  1 32
{% endhighlight %}



{% highlight r %}
dim(layer$get_weights()[[2]])
{% endhighlight %}



{% highlight text %}
## [1] 32
{% endhighlight %}


{% highlight r %}
par(mar = c(0,0,0,0))
par(mfrow = c(8, 4))
for (i in 1:32) {
  wg <- layer$get_weights()[[1]][,,,i]
  im <- abs(wg) / max(abs(wg))
  sg <- sign(wg)
  plot(0,0,xlim=c(0,1),ylim=c(0,1),axes= FALSE,type = "n")
  rasterImage(im,0,0,1,1,interpolate=FALSE)
  box()
  text(row(sg) / 3 - 1/6, col(sg) / 3 - 1/6,
       label = sg, col = "salmon", cex = 3)
}
{% endhighlight %}

![plot of chunk unnamed-chunk-10](../assets/2017-10-31-class18/unnamed-chunk-10-1.png)

